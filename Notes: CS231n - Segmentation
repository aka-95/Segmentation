Notes: CS231n - Justin Johnson - Segmentation
- segmentation as a task - assign labels to each pixel - output usually comes from the softmax layer and has form {n_classes x image widht x image height} 
  where n classes is th no .of classes of segmentation which are then  argmaxed to assign labels to each pixel - loss used is generally cross entropy 
  - data is very difficult to annotate

  
- Simplest approach - sliding window and classify - impractical
- Better - CNNs without FCs - but without downsampling, the compute requirements become prohibitively expensive - (ie 512 depth channels of 1024x2048 image) 
  but we know depth is essential for good learning, so Solution - downsample the images (std. maxpooling) and then upsample them (using NN, 
  Transposed conv(learned weights used), bed of nails, max unpooling(remenber the max index while pooling))

- Classifation +Localization as a task - two FC Layers/subnets to predict localization bbox coords(regression loss) and class confidences(classification loss) 
  respectively. issues arise when backproping if either of the two losses dominate. In such cases, hyperparameter is used to weight the losses appropriately. 
  this is tricky because our loss value itself is being changed by the change in hyperparameter so it is important to have a look at some other value that we 
  care about for tuning this hyperparameter. 
  Aside - pose estimation from a single image can be done by regressing like bboxes. ie regress for positions of different joints
  
- PASCAL-VOC is a relatively easy dataset to quote results on.

- Object detection as a problem - is trickier than localization because the number of possible objects is unlimited (so, sliding window kind of approach is needed) 
  or bounding boxes/proposal regions which is then followed by classification of regions . 
  Eg: 
  class 1 - region proposal based
  RCNN - Region Proposals found using traditional methods (~2000), then 
  varying size bounding boxes are warped to a fixed size so that they can be used inside CNNs and classification (additional class called background used to account 
  for the object less regions) is done along with a correction offset being predicted to enhance the bounding box. slow test time (~47 sec)
  Eg: Fast RCNN - instead of using rois on the input image, take convolutional features extracted from image and map the region proposals onto them - basically 
  reduce the time by sharing convolutional operations/features - test time much faster and dominated by region proposal generator (~2sec) - roi pooling
  Eg: Faster RCNN - instead of using mapping for region proposals, learn them too, - 4 tasks and so multi task loss - mmreduces the test time to (~0.2sec)
  
  class2 - single shot / detection without region proposals
  YOLO - we divide the image into 7x7 base grid and each grid checks out a fixed number of rectangles centered on it for objects(and classes) and class 
  confidence. so each region proposal doesnt havet to be worked on sequentially hence faster. 
  
  Broadly speaking, object detection is more accurate for region proposal based things and faster for single shot things.
  
  Mask RCNN - Faster RCNN backbone - ROI proposals followed by mini segmentation over all the ROIs - testing take 5fps on a GPU - 
